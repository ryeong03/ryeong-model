import json
import random
import requests
from typing import Dict, List, Optional, Callable
from datetime import datetime
from dataclasses import dataclass
from functools import lru_cache
import logging

from .personas import PersonaConfig, create_persona_from_user_data

@dataclass
class ContentInfo:
    """ì½˜í…ì¸  ì •ë³´ë¥¼ ìœ„í•œ ë°ì´í„° í´ë˜ìŠ¤"""
    index: int
    content_id: str
    type: str
    title: str
    url: str
    description: str

class LLMUserSimulator:
    """
    Ollamaë¥¼ í™œìš©í•œ ì‚¬ìš©ì ì‹œë®¬ë ˆì´í„°.
    í˜ë¥´ì†Œë‚˜ DBì—ì„œ ê°€ì ¸ì˜¨ MBTIì™€ íˆ¬ì ë ˆë²¨ë¡œ PersonaConfigë¥¼ ìƒì„±í•˜ì—¬ 
    ì½˜í…ì¸  ì¶”ì²œì— ëŒ€í•œ ë°˜ì‘ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    """
    
    # ì½˜í…ì¸  íƒ€ì…ë³„ ê¸°ë³¸ ì²´ë¥˜ì‹œê°„ ë²”ìœ„ (ì´ˆ)
    CONTENT_DWELL_TIMES = {
        "youtube": (60, 600),    # 1-10ë¶„
        "blog": (90, 480),       # 1.5-8ë¶„
        "news": (30, 300),       # 30ì´ˆ-5ë¶„
        "default": (30, 300)
    }
    
    def __init__(
        self, 
        ollama_url: str = "http://localhost:11434",
        model: str = "llama3.2:2b",  # ê¸°ë³¸ê°’, experiment.yamlì—ì„œ ì˜¤ë²„ë¼ì´ë“œë¨
        debug: bool = False
    ):
        """
        Args:
            ollama_url (str): Ollama ì„œë²„ URL
            model (str): ì‚¬ìš©í•  ëª¨ë¸ëª…
            debug (bool): ë””ë²„ê¹… ì¶œë ¥ ì—¬ë¶€
        """
        self.ollama_url = ollama_url.rstrip('/')  # í›„í–‰ ìŠ¬ë˜ì‹œ ì œê±°
        self.model = model
        self.debug = debug
        
        # ì—°ê²° ìƒíƒœ ìºì‹±
        self._connection_checked = False
        self._is_available = False
        
        # API ì„¤ì •
        self._api_config = {
            "timeout": 30,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 1000
            }
        }
    
    @property
    def is_available(self) -> bool:
        """Ollama ì„œë²„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ (ì§€ì—° ì´ˆê¸°í™”)"""
        if not self._connection_checked:
            self._is_available = self._test_ollama_connection()
            self._connection_checked = True
        return self._is_available
    
    @lru_cache(maxsize=1)
    def _test_ollama_connection(self) -> bool:
        """Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ (ìºì‹±ë¨)"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code != 200:
                logging.warning(f"Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return False
                
            models = response.json().get("models", [])
            model_names = [model.get("name", "") for model in models]
            
            if self.model not in model_names:
                logging.warning(f"ëª¨ë¸ {self.model}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model_names}")
                return False
                
            logging.info(f"Ollama ì„œë²„ ì—°ê²° ì„±ê³µ. ëª¨ë¸ {self.model} ì‚¬ìš© ê°€ëŠ¥.")
            return True
            
        except requests.RequestException as e:
            logging.warning(f"Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def simulate_user_response(
        self, 
        persona_id: int,
        mbti: str,
        investment_level: int,
        recommended_contents: List[Dict],
        current_context: Optional[Dict] = None
    ) -> str:
        """
        í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ë°˜ì‘ ì‹œë®¬ë ˆì´ì…˜.
        
        Args:
            persona_id: í˜ë¥´ì†Œë‚˜ ID
            mbti: MBTI ìœ í˜•
            investment_level: íˆ¬ì ë ˆë²¨ (1=ì´ˆë³´, 2=ì¤‘ê¸‰, 3=ê³ ê¸‰)
            recommended_contents: ì¶”ì²œëœ ì½˜í…ì¸  ë¦¬ìŠ¤íŠ¸
            current_context: í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì˜µì…˜)
            
        Returns:
            str: LLM ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        # í˜ë¥´ì†Œë‚˜ ìƒì„±
        persona = create_persona_from_user_data(
            user_id=persona_id,
            mbti=mbti,
            investment_level=investment_level
        )

        if not recommended_contents:
            return ""
        
        # Ollama ì—°ê²° í™•ì¸
        if not self.is_available:
            raise RuntimeError("Ollama ì„œë²„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # LLM ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        return self._ollama_based_simulation(
            persona, recommended_contents, current_context
        )
    
    def _ollama_based_simulation(
        self, 
        persona: PersonaConfig, 
        recommended_contents: List[Dict],
        current_context: Optional[Dict] = None
    ) -> str:
        """Ollamaë¥¼ í™œìš©í•œ ì‚¬ìš©ì ë°˜ì‘ ì‹œë®¬ë ˆì´ì…˜ (ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜)"""
        
        # ì½˜í…ì¸  ì •ë³´ ì¤€ë¹„
        contents_info, content_ids = self._prepare_content_info(recommended_contents)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        user_prompt = self._build_user_prompt(persona, contents_info, content_ids)
        
        # ë””ë²„ê¹… ì¶œë ¥
        if self.debug:
            print("ğŸ“ LLMì—ê²Œ ë³´ë‚´ëŠ” í”„ë¡¬í”„íŠ¸:")
            print("-" * 40)
            print(user_prompt)
            print("-" * 40)
            print()
        
        # API í˜¸ì¶œ
        response = self._call_ollama_api(user_prompt)
        
        # ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜
        llm_output = response.get("response", "")
        
        if self.debug:
            print("ğŸ¤– LLM ì›ë³¸ ì‘ë‹µ:")
            print("-" * 40)
            print(llm_output)
            print("-" * 40)
            print()
        
        return llm_output
    
    def _prepare_content_info(self, recommended_contents: List[Dict]) -> tuple[List[ContentInfo], List[str]]:
        """ì½˜í…ì¸  ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¤€ë¹„"""
        contents_info = []
        content_ids = []
        
        for i, content in enumerate(recommended_contents):
            content_id = content.get("id", f"content_{i}")
            content_ids.append(content_id)
            
            # ContentInfo ê°ì²´ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            info = ContentInfo(
                index=i,
                content_id=content_id,
                type=content.get("type", "unknown"),
                title=content.get("title", "ì œëª© ì—†ìŒ"),
                url=content.get("url", ""),
                description=content.get("description", "ì„¤ëª… ì—†ìŒ")[:200]
            )
            contents_info.append(info)
        
        return contents_info, content_ids
    
    ## í”„ë¡¬í¬íŠ¸ì—”ì§€ë‹ˆì–´ë§ í•˜ëŠ” ë¶€ë¶„
    def _build_user_prompt(
        self, 
        persona: PersonaConfig, 
        contents_info: List[ContentInfo], 
        content_ids: List[str],
    ) -> str:
        """
        LLMì—ê²Œ **ë‹¨ í•˜ë‚˜ì˜ ìœ íš¨ JSON ê°ì²´**ë§Œ ë°˜í™˜í•˜ë„ë¡ ìš”êµ¬.
        - ì™¸ë¶€ í‚¤: responsesÂ·timestampÂ·persona_idÂ·simulation_method
        - ë‚´ë¶€ ë°°ì—´ ìš”ì†Œ ìˆ˜ == len(content_ids)
        """
        
        # 1) ì½˜í…ì¸  ì„¤ëª… ì¤„
        content_info_text = "\n".join(
            f"{info.content_id}: {info.type} - {info.title}\n   ì„¤ëª…: {info.description}" 
            for info in contents_info
        )
        
        # 2) ê³µí†µ ë©”íƒ€ê°’
        persona_id = f"{persona.mbti}_{persona.investment_level}_{persona.user_id}"
        
        # 3) í”„ë¡¬í”„íŠ¸ ë³¸ë¬¸
        prompt = f"""
ë„ˆëŠ” ì£¼ì‹ ì½˜í…ì¸  í´ë¦­ ì‹œë®¬ë ˆì´í„°ë‹¤. ì…ë ¥ ì •ë³´ì— ë”°ë¥¸ í˜ë¥´ì†Œë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–‰ë™í•´ë¼.

### ì…ë ¥ ì •ë³´
- persona_id: {persona_id}
- íˆ¬ìë“±ê¸‰(investment_level): {persona.investment_level}
- ìœ„í—˜ ì„±í–¥(risk_tolerance): {persona.risk_tolerance:.1f}
- ë³€ë™ì„± ìˆ˜ìš© ì •ë„(volatility_tolerance): {persona.volatility_tolerance:.1f}
- ë°°ë‹¹ ì„ í˜¸ ì •ë„(dividend_preference): {persona.dividend_preference:.1f}
- ê²°ì • ì†ë„(decision_speed): {persona.decision_speed:.1f}
- ì‚¬íšŒì  ì˜í–¥ ë¯¼ê°ë„(social_influence): {persona.social_influence:.1f}
- íˆ¬ì ê¸°ê°„(investment_horizon): {persona.investment_horizon.value}
- ë¶„ì„ ì„ í˜¸(analysis_preference): {persona.analysis_preference.value}
- ì „ë¬¸ê°€ ì˜ì¡´ë„(expert_reliance): {persona.expert_reliance:.1f}
- ì±„ë„ ê°€ì¤‘ì¹˜: ìœ íŠœë¸Œ {persona.preferences['youtube']:.1f}, ë¸”ë¡œê·¸ {persona.preferences['blog']:.1f}, ë‰´ìŠ¤ {persona.preferences['news']:.1f}

### í›„ë³´ ì½˜í…ì¸ 
{content_info_text}

### ì¶œë ¥ í˜•ì‹ (**ì•„ë˜ JSON ë°°ì—´ì„ ê·¸ëŒ€ë¡œ, ê°’ë§Œ ì±„ì›Œì„œ** ë°˜í™˜) â€” ë‹¤ë¥¸ ê¸€ìÂ·ê³µë°±Â·ë°±í‹±Â·ì„¤ëª… ê¸ˆì§€
[
{chr(10).join(
    f'  {{"content_id": "{cid}", "clicked": true/false, "dwell_time_seconds": 0}}'
    + (',' if i < len(content_ids) - 1 else '')
    for i, cid in enumerate(content_ids)
)}
]

### íˆ¬ì ë ˆë²¨ ì •ì˜
- investment_levelì€ 1(ì´ˆë³´Â·ì†Œì•¡) ~ 5(ì „ë¬¸Â·ëŒ€ê·œëª¨) ì‚¬ì´ ì •ìˆ˜.

### ê³µí†µ ë¹„ìœ¨ ì •ì˜
- ëª¨ë“  ë¹„ìœ¨ ê°’ì€ 0.0 ~ 1.0 ì‚¬ì´ ì‹¤ìˆ˜.
- ê°’ì´ í´ìˆ˜ë¡ í•´ë‹¹ ì†ì„±ì´ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘(ì„ í˜¸Â·ë¯¼ê°ë„Â·ê°•ë„)ì´ í¬ë‹¤.
  ì˜ˆ) channel_weight 1.0 â†’ ë°˜ë“œì‹œ ìš°ì„  ê³ ë ¤, 0.0 â†’ ì „í˜€ ê³ ë ¤ ì•ˆ í•¨.

### í•˜ë“œ ê·œì¹™
1. ë°°ì—´ ê¸¸ì´ëŠ” **{len(content_ids)}** ê°œ.
2. clicked == false âœ dwell_time_seconds == 0  
   clicked == true  âœ dwell_time_seconds âˆˆ [30,300] (ì •ìˆ˜)
3. í‚¤Â·ë”°ì˜´í‘œÂ·ì½¤ë§ˆÂ·ëŒ€ì†Œë¬¸ì ì¼ì²´ ìˆ˜ì • ê¸ˆì§€.
4. JSON ë°°ì—´ ì´ì™¸ í…ìŠ¤íŠ¸Â·ë§ˆí¬ë‹¤ìš´ ë¸”ë¡Â·ì£¼ì„ **ì ˆëŒ€ ì¶œë ¥ ê¸ˆì§€**.
"""
        return prompt.strip()

    def _call_ollama_api(self, prompt: str) -> Dict:
        """Ollama API í˜¸ì¶œ (ìµœì í™”ë¨)"""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": self._api_config["options"]
        }
        
        response = requests.post(
            f"{self.ollama_url}/api/generate",
            json=payload,
            timeout=self._api_config["timeout"]
        )
        
        if response.status_code != 200:
            raise Exception(f"Ollama API ì˜¤ë¥˜: {response.status_code} - {response.text}")
        
        return response.json()
    
    def reset_connection_cache(self) -> None:
        """ì—°ê²° ìºì‹œ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ ë˜ëŠ” ì¬ì—°ê²° ì‹œ ì‚¬ìš©)"""
        self._connection_checked = False
        self._is_available = False
        self._test_ollama_connection.cache_clear() 